@inproceedings{pfeffer2001intelligent,
  title={Intelligent indexing and semantic retrieval of multimodal documents},
  author={Pfeffer, Michael and Estevez, Elsa and De Giusti, Marisa R},
  booktitle={Proceedings of the International Conference on Information Technology: Coding and Computing},
  pages={52--57},
  year={2001},
  organization={IEEE}
}

@article{bast2016semantic,
  title={Semantic search on text and knowledge bases},
  author={Bast, Hannah and Buchhold, Bj√∂rn and Haussmann, Elmar},
  journal={Foundations and Trends in Information Retrieval},
  volume={10},
  number={2-3},
  pages={119--271},
  year={2016},
  publisher={Now Publishers, Inc.}
}

@article{kiros2014unifying,
  title={Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models},
  author={Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Richard S},
  journal={arXiv preprint arXiv:1411.2539},
  year={2014}
}


@inproceedings{frome2013devise,
  title={DeViSE: A deep visual-semantic embedding model},
  author={Frome, Andrea and Corrado, Greg S and Shlens, Jonathon and Bengio, Samy and Dean, Jeff and Mikolov, Tomas},
  booktitle={Advances in neural information processing systems},
  year={2013}
}

@inproceedings{song2019polysemous,
  title={Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval},
  author={Song, Yale and Soleymani, Mohammad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1979--1988},
  year={2019}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={4171--4186},
  year={2019},
  publisher={Association for Computational Linguistics}
}

@inproceedings{reimers2019sentence,
  title={Sentence-BERT: Sentence embeddings using Siamese BERT-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={EMNLP-IJCNLP},
  year={2019}
}

@inproceedings{li2019visualbert,
  title={VisualBERT: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  booktitle={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{tautkute2019deepstyle,
  title={DeepStyle: Multimodal Search Engine for Fashion and Interior Design},
  author={Tautkute, Ivona and Trzcinski, Tomasz and Skorupa, Aleksander and Brocki, Lukasz and Marasek, Krzysztof},
  journal={IEEE Access},
  volume={7},
  pages={84613--84628},
  year={2019},
  doi={10.1109/ACCESS.2019.2923552}
}

@inproceedings{chun2021probabilistic,
  title={Probabilistic Embeddings for Cross-Modal Retrieval},
  author={Chun, Sanghyuk and Oh, Seong Joon and de Rezende, Rafael Sampaio and Kalantidis, Yannis and Larlus, Diane},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={10609--10618},
  year={2021},
  doi={10.1109/CVPR46437.2021.01045}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Jack and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Miles and Krueger, Gretchen and Sutskever, Ilya},
  booktitle={ICML},
  year={2021}
}

@inproceedings{elizalde2023clap,
  title={CLAP: Learning audio-text representations from scratch},
  author={Elizalde, Benjamin and Wang, Yuan Gong and Liu, Po-Han and Subramanian, Ajay and Fonseca, Eduardo and Kim, Chiyuan and Harwath, David and Glass, James},
  booktitle={ICASSP},
  year={2023}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zachary and Pham, Hieu and Le, Quoc V and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={ICML},
  year={2021}
}

@inproceedings{gong2023boon,
  title={Boon: A Neural Search Engine for Cross-Modal Information Retrieval},
  author={Gong, Yan and Cosma, Georgina},
  booktitle={Proceedings of the 1st International Workshop on Deep Multimodal Learning for Information Retrieval (MMIR '23)},
  pages={29--37},
  year={2023},
  publisher={ACM},
  doi={10.1145/3606040.3617440}
}


@inproceedings{liu2025multimodal,
  title={Multimodal Semantic Retrieval for Product Search},
  author={Liu, Dong and Lopez Ramos, Esther},
  booktitle={Proceedings of the EReL@MIR Workshop at The Web Conference (WWW) 2025},
  year={2025},
  note={arXiv:2501.07365},
  url={https://arxiv.org/abs/2501.07365}
}


@inproceedings{li2022blip,
  title={BLIP: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven CH},
  booktitle={ICML},
  year={2022}
}

@inproceedings{li2023blip2,
  title={BLIP-2: Bootstrapped language-image pretraining with frozen image encoders and large language models},
  author={Li, Junnan and Zhang, Dongxu and Xiong, Caiming and Hoi, Steven CH},
  booktitle={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@inproceedings{girdhar2023imagebind,
  title={ImageBind: One embedding space to bind them all},
  author={Girdhar, Rohit and et al.},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{lu2023unified,
  title={Unified-IO: A unified model for vision, language, and multimodal tasks},
  author={Lu, Jiasen and et al.},
  booktitle={arXiv preprint arXiv:2210.04150},
  year={2023}
}

@inproceedings{xu2023mmsearch,
  title={MMSearch: A multimodal search benchmark},
  author={Xu, Yichong and Zhang, Tianlang and et al.},
  booktitle={arXiv preprint arXiv:2305.12384},
  year={2023}
}

@inproceedings{liu2023univldr,
  title={Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval},
  author={Liu, Zhenghao and Xiong, Chenyan and Lv, Yuanhuiyi and Liu, Zhiyuan and Yu, Ge},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2023},
  url={https://arxiv.org/abs/2209.00179}
}

@article{li2024unifying,
  title={Unifying visual-semantic embeddings with multimodal LLMs for retrieval},
  author={Li, Dongxu and et al.},
  journal={arXiv preprint arXiv:2401.01960},
  year={2024}
}
